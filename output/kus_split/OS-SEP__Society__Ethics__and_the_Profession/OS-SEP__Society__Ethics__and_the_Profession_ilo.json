{
  "title": "OS-SEP: Society, Ethics, and the Profession",
  "Illustrative Learning Outcomes": {
    "KA Core": "1. Explain advantages and disadvantages of finding and addressing bugs in open-source kernels.\n2. Contextualize history and positive and negative impact of Linux as an open-source product.\n3. List complications with reliance on operating systems past end-of-life.\n4. Understand differences in finding and addressing bugs for various operating systems payment\nmodels.\nProfessional Dispositions\n● Proactive: Students must anticipate the security and performance implications of how operating\nsystems components are used.\n● Meticulous: Students must carefully analyze the implications of operating system mechanisms on\nany project.\nMathematics Requirements\nRequired:\n● MSF-Discrete\nCourse Packaging Suggestions\nIntroductory Course to include the following:\n215\n● OS-Purpose (3 hours)\n● OS-Principles (3 hours)\n● OS-Concurrency (7 hours)\n● OS-Scheduling (3 hours)\n● OS-Process (3 hours)\n● OS-Memory (4 hours)\n● OS-Protection (4 hours)\n● OS-Devices (2 hours)\n● OS-Files (2 hours)\n● OS-Virtualization (3 hours)\n● OS-Advanced-Files (2 hours)\n● OS-Real-time (1 hour)\n● OS-Faults (1 hour)\n● OS-SEP (4 hours)\nPrerequisites:\n● AR-Assembly\n● AR-Memory\n● AR-Reliability\n● AR-IO\n● AR-Organization\n● MSF-Discrete\nCourse objectives: Students should understand the impact and implications of operating system\nresource management in terms of performance and security. They should understand and implement\ninter-process communication mechanisms safely. They should be able to differentiate between the use\nand evaluation of open-source and/or proprietary operating systems. They should understand\nvirtualization as a feature of safe modern operating system implementation.\nCommittee\nChair: Monica D. Anderson, University of Alabama, Tuscaloosa, AL, USA\nMembers:\n● Qiao Xiang, Xiamen University, Xiamen, China\n● Mikey Goldweber, Denison University, Granville, OH, USA\n● Marcelo Pias, Federal University of Rio Grande (FURG), Rio Grande, RS, Brazil\n● Avi Silberschatz, Yale University, New Haven, CT, USA\n● Renzo Davoli, University of Bologna, Bologna, Italy\n216\nParallel and Distributed Computing (PDC)\nPreamble\nParallel and distributed programming arranges, coordinates, and controls multiple computations\noccurring at the same time across different places. The ubiquity of parallelism and distribution are\ninevitable consequences of increasing numbers of gates in processors, processors in computers, and\ncomputers everywhere that may be used to improve performance compared to sequential programs,\nwhile also coping with the intrinsic interconnectedness of the world, and the possibility that some\ncomponents or connections fail or behave maliciously. Parallel and distributed programming removes\nthe restrictions of sequential programming that require computational steps to occur in a serial order in\na single place, revealing further distinctions, techniques, and analyses applying at each layer of\ncomputing systems.\nIn most conventional usage, “parallel” programming focuses on establishing and coordinating multiple\nactivities that may occur at the same time, “distributed” programming focuses on establishing and\ncoordinating activities that may occur in different places, and “concurrent” programming focuses on\ninteractions of ongoing activities with each other and the environment. However, all three terms may\napply in most contexts. Parallelism generally implies some form of distribution because multiple\nactivities occurring without sequential ordering constraints happen in multiple physical places (unless\nthey rely on context-switching or quantum effects). Conversely, actions in different places need not\nbear any specific sequential ordering with respect to each other in the absence of communication\nconstraints.\nParallel, distributed, and concurrent programming techniques form the core of High Performance\nComputing (HPC), distributed systems, and increasingly, nearly every computing application. The PDC\nknowledge area has evolved from a diverse set of advanced topics into a central body of knowledge\nand practice, permeating almost every other aspect of computing. Growth of the field has occurred\nirregularly across different subfields of computing, sometimes with different goals, terminology, and\npractices, masking the considerable overlap of basic ideas and skills that are the primary focus of this\nknowledge area. Nearly every problem with a sequential solution also admits parallel and/or distributed\nsolutions; additional problems and solutions arise only in the context of concurrency. Nearly every\napplication domain of parallel and distributed computing is a well-developed area of study and/or\nengineering too large to enumerate.\nChanges since CS2013\nThis knowledge area has been refactored to focus on commonalities across different forms of parallel\nand distributed computing, also enabling more flexibility in KA Core coverage, with more guidance on\ncoverage options.\nOverview\nThis knowledge area is divided into five knowledge units, each with CS Core and KA Core topics that\nextend but do not overlap CS Core coverage that appears in other knowledge areas. The five\n217\nknowledge units cover: The nature of parallel and distributed Programs and their execution;\nCommunication (via channels, memory, or shared data stores), Coordination among parallel\nactivities to achieve common outcomes; Evaluation with respect to specifications, and Algorithms\nacross multiple application domains.\nCS Core topics span approaches to parallel and distributed computing but restrict coverage to those\nthat apply to nearly all of them. Learning outcomes include developing small programs (in a choice of\nseveral styles) with multiple activities and analyzing basic properties. The topics and hours do not\ninclude coverage of specific languages, tools, frameworks, systems, and platforms needed as a basis\nfor implementing and evaluating concepts and skills. The topics also avoid reliance on specifics that\nmay vary widely (for example GPU programming vs cloud container deployment scripts), Prerequisites\nfor CS Core coverage include the following.\n● SDF-Fundamentals: programs, executions, specifications, implementations, variables, arrays,\nsequential control flow, procedural abstraction and invocation, Input/Output.\n● SF-Overview: Layered systems, state machines, reliability.\n● AR-Assembly, AR-Memory: von Neumann architecture, memory hierarchy.\n● MSF-Discrete: Discrete structures including directed graphs.\nAdditionally, Foundations of Programming Languages (FPL) may be treated as a prerequisite,\ndepending on other curricular choices. CS Core requires familiarity with languages and platforms that\nenable construction of parallel and distributed programs. Also, PDC includes definitions of safety,\nliveness, and related concepts that are covered with respect to language properties and semantics in\nFPL. Similarly, PDC CS Core includes concepts that are further developed in the context of network\nprotocols in Networking and Communication (NC), Operating Systems (OS), and Security (SEC), that\ncould be covered in any order.\nKA Core topics in each unit are of the form “one or more of the following” for a la carte topics extending\nassociated core topics. Any selection of KA-core topics meeting the KA Core hour requirement\nconstitutes fulfillment of the KA Core. This structure permits variation in coverage depending on the\nfocus of any given course (see below for examples). Depth of coverage of any KA Core subtopic is\nexpected to vary according to course goals. For example, shared-memory coordination is a central\ntopic in multicore programming, but much less so in most heterogeneous systems, and conversely for\nbulk data transfer. Similarly, fault tolerance is central to the design of distributed information systems,\nbut much less so in most data-parallel applications.\nCore Hours\nKnowledge Unit CS Core hours KA Core hours\nPrograms 2 2\nCommunication 2 6\nCoordination 2 6\n218\nEvaluation 1 3\nAlgorithms 2 9\nSociety, Ethics, and the Profession Included in SEP hours\nTotal 9 26\nKnowledge Units"
  }
}