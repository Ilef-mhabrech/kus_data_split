{
  "title": "SE-Validation: Software Verification and Validation",
  "Illustrative Learning Outcomes": {
    "CS Core": "1. Explain why testing is important.\n2. Distinguish between program validation and verification.\n3. Describe different objectives of testing.\n4. Compare and contrast the different types and levels of testing (regression, unit, integration,\nsystems, and acceptance).",
    "KA Core": "5. Describe techniques for creating a test plan and generating test cases.\n6. Create a test plan for a medium-size code segment which includes a test matrix and generation of\ntest data and inputs.\n7. Implement a test plan for a medium-size code segment.\n8. Identify the fundamental principles of test-driven development methods and explain the role of\nautomated testing in these methods.\n9. Discuss issues involving the testing of object-oriented software.\n10. Describe mocking and dependency injection and their application.\n11. Undertake, as part of a team activity, a code review of a medium-size code segment.\n12. Describe the role that tools can play in the validation of software.\n13. Automate the testing in a small software project.\n14. Explain the roles, pros, and cons of pre-commit and post-commit testing.\n15. Discuss the tradeoffs between test coverage and test throughput/latency and how this can impact\nverification.\n248\n16. Use a defect tracking tool to manage software defects in a small software project.\n17. Discuss the limitations of testing in certain domains.\nNon-Core:\n18. Describe and compare different tools for verification and validation.\n19. Automate the use of different tools in a small software project.\n20. Explain how and when random numbers should be used in testing.\n21. Describe approaches for fault estimation.\n22. Estimate the number of faults in a small software application based on fault density and fault\nseeding.\n23. Describe throughput and latency and provide examples of each.\n24. Explain speedup and the different forms of scaling and how they are computed.\n25. Describe common performance bottlenecks.\n26. Describe statistical methods and best practices for benchmarking software.\n27. Explain techniques for and challenges with measuring time when constructing a benchmark.\n28. Identify the figures of merit, construct and run a benchmark, and statistically analyze and visualize\nthe results for a small software project.\n29. Describe techniques and issues with testing asynchronous, concurrent, and parallel software.\n30. Create a test plan for a medium-size code segment which contains asynchronous, concurrent,\nand/or parallel code, including a test matrix and generation of test data and inputs.\n31. Describe techniques for the verification and validation of non-code artifacts."
  }
}